# 테스트 자동화

소프트웨어 개발에서 **테스트 자동화**는 필수적이지만, 테스트 코드를 일일이 작성하는 일은 종종 번거롭고 지루하게 느껴집니다. 그렇다고 테스트를 생략하면 작은 변경으로도 기존 기능이 망가지는 **회귀**(regression)를 놓치기 쉽고, 버그가 늦게 발견되어 개발 속도가 떨어질 수 있습니다. 따라서 자동화된 테스트 스위트를 갖춘 프로젝트는 더 높은 안정성과 코드 품질을 확보하게 됩니다. 다행히 **GitHub Copilot**과 같은 AI 코딩 도우미를 활용하면 이러한 테스트 작성 과정을 훨씬 **빠르고 효율적**으로 진행할 수 있습니다.

이번 강의에서는 Python과 VS Code 환경을 기반으로 **테스트 자동화의 개념과 중요성**을 알아보고, 파이썬의 대표적인 테스트 프레임워크인 **unittest**와 **pytest**의 기본 사용법을 살펴봅니다. 그리고 **GitHub Copilot**을 활용해 테스트 코드를 자동 생성하는 방법과 **Copilot Chat**으로 테스트 작성 지원 및 코드 리팩토링을 수행하는 방법을 실습해볼 것입니다. 마지막으로, 작성한 테스트를 **테스트 커버리지** 측정과 **지속적 통합**(CI)과 연계하는 방안까지 간단히 언급하겠습니다. 자, 시작해보겠습니다!

## 1. 테스트 자동화의 개념과 중요성

**테스트 자동화**란 개발자가 작성한 코드가 의도한 대로 동작하는지 검증하는 **테스트 코드를 작성**하고 이를 자동으로 실행하는 것을 의미합니다. 한번 테스트를 작성해 두면 코드가 변경될 때마다 수동으로 일일이 기능을 확인하지 않고도, 자동화된 테스트 실행으로 **빠르게 피드백**을 얻을 수 있습니다. 이러한 테스트 자동화가 주는 중요 이점들은 다음과 같습니다:

- **회귀 방지 및 안정성 확보**: 새로운 기능 추가나 리팩터링 시 기존에 잘 동작하던 기능이 망가지지 않았는지 자동으로 확인하여, 의도치 않은 **회귀 발생을 방지**합니다. 테스트를 통과한다는 것은 코드 변경에도 기존 동작이 유지되었음을 의미하므로, 리팩터링을 안심하고 진행할 수 있습니다.  
- **개발 속도 향상**: 자동화된 테스트는 코드 수정 후 일일이 수동 테스트를 하는 시간을 줄여 주어, 버그를 **초기에 발견**하고 빠르게 수정하게 합니다. 덕분에 전체 개발 사이클이 빨라지고, 이후 단계에서 발생할 수 있는 큰 문제를 미리 차단하여 디버깅에 소모되는 시간도 단축됩니다.  
- **품질 확보 및 신뢰도 향상**: 충분한 테스트 커버리지를 갖춘 코드는 **품질에 대한 자신감**을 줍니다. 새로운 기능을 추가할 때도 기존 테스트들이 일종의 안전망이 되어주기 때문에, 코드베이스의 **무결성**과 **신뢰도**가 높아집니다. (테스트 코드는 함수의 용도와 기대 결과를 보여주는 **실행 가능한 문서**로서의 역할도 합니다.)

> 💡 **Tip:** 테스트의 중요성은 *Test-Driven Development* (TDD) 방법론으로도 강조됩니다. TDD에서는 구현 전에 테스트를 먼저 작성하여 요구사항을 명확히 하고, 테스트를 모두 통과할 때까지 코드를 개선해나갑니다. 이처럼 테스트는 단순한 검증을 넘어 개발 과정의 가이드 역할도 할 수 있습니다.

## 2. 테스트의 기본 구성 요소

효과적인 테스트 코드를 작성하려면 **테스트 케이스**를 구성하는 요소를 이해해야 합니다. 일반적으로 하나의 단위 테스트는 다음 네 가지 요소로 이루어집니다:

- **테스트 대상**: 검증하려는 대상 코드입니다 (예: 특정 함수나 메서드). 해당 코드가 정상 동작하는지 확인하고자 합니다.  
- **입력**: 테스트 대상에 제공할 **값이나 환경**입니다. 함수에 넘길 인자 값이나 객체의 초기 상태 등이 이에 해당합니다.  
- **예상 결과**: 입력을 통해 함수가 반환해야 하는 값이나 발생해야 하는 **기대 동작**입니다. 정상적인 출력일 수도 있고, 잘못된 입력에 대한 예외(Exception) 발생일 수도 있습니다.  
- **검증 로직**: 실제 결과가 예상 결과와 일치하는지 확인하는 코드입니다. 보통 **assert** 구문이나 테스트 프레임워크의 검사 메서드를 사용하여 일치 여부를 판단합니다.

이러한 요소들을 종합하여 테스트를 구성합니다. 예를 들어, 두 수를 더하는 함수 `add(a, b)`가 있다고 가정해봅시다. 우리는 `add` 함수(테스트 대상)에 **2와 3**이라는 입력을 주었을 때 **5**를 반환할 것(예상 결과)을 기대하며, 실제 반환값을 확인하여 검증합니다:

```python
# 예시: add 함수와 그에 대한 단위 테스트 구성 요소
def add(a, b):
    return a + b

result = add(2, 3)            # 테스트 대상: add 함수, 입력: 2와 3
assert result == 5            # 예상 결과: 5, 검증: 결과가 5인지 assert로 확인
```

위 예에서 `add(2,3)`의 결과가 예상대로 5라면 테스트를 통과한 것이고, 만약 결과가 다르면 assert에서 실패하여 테스트가 실패함을 나타냅니다. 이런 식으로 입력과 기대 결과를 정해두고 검증하는 작은 단위의 테스트들을 여러 개 만들어두면, 코드의 각 부분이 의도대로 동작하는지를 꼼꼼히 확인할 수 있습니다.  

> 💡 **Assert 사용:** 파이썬에서는 기본 키워드 `assert`를 사용하거나, 테스트 프레임워크에서 제공하는 전용 assert 함수를 사용해 검증합니다. 예를 들어 `assert func(x) == y` 형태로 작성하면, 조건이 False일 때 AssertionError가 발생하면서 해당 테스트가 실패합니다.

## 3. Python 테스트 프레임워크 소개 (unittest vs pytest)

파이썬에서 테스트 코드를 체계적으로 작성하고 실행하기 위해 **테스트 프레임워크**를 활용합니다. 대표적으로 **unittest**(파이썬 표준 라이브러리)와 **pytest**(서드파티 프레임워크)가 널리 사용됩니다.

- **unittest**: 자바의 JUnit과 유사한 xUnit 스타일의 프레임워크입니다. `unittest.TestCase` 클래스를 상속한 테스트 클래스 내부에 `test_`로 시작하는 메서드를 정의하고, `self.assertEqual`, `self.assertTrue` 같은 다양한 **assert 메서드**를 사용해 결과를 검증합니다. 표준 라이브러리에 내장되어 있어 별도 설치 없이 사용할 수 있습니다.  
- **pytest**: 보다 **파이썬다운** 방식의 테스트 프레임워크로, 심플한 문법과 강력한 확장 기능을 제공합니다. 테스트 함수를 간단히 `def test_something():` 형태로 작성하고, 일반 `assert` 문으로 기대 결과를 검증하면 됩니다. **fixture**나 **parametrize**와 같은 기능으로 복잡한 테스트도 깔끔하게 작성할 수 있고, 플러그인을 통해 기능을 확장할 수도 있습니다. (pytest를 사용하려면 `pip install pytest`로 별도 설치가 필요합니다.)

두 프레임워크 모두 장단점이 있지만, 기본적인 단위 테스트 작성이라는 관점에서는 둘 다 유사한 역할을 합니다. 이번 실습에서는 코드 작성이 비교적 간결한 **pytest 스타일**로 예시를 보여드리겠습니다.

예를 들어, **팩토리얼 함수**를 구현하고 이에 대한 단위 테스트를 작성해보겠습니다. 팩토리얼 함수 `factorial(n)`은 1부터 n까지의 정수를 모두 곱한 값이며, 만약 음수가 입력되면 정의되지 않으므로 `ValueError` 예외를 발생시킨다고 가정하겠습니다:

```python
# factorial.py - 테스트 대상 함수 구현
def factorial(n: int) -> int:
    """n의 팩토리얼을 반환한다. n이 음수이면 ValueError 발생."""
    if n < 0:
        raise ValueError("음수 값에 대한 팩토리얼은 정의되지 않습니다.")
    if n <= 1:
        return 1
    return n * factorial(n - 1)
```

이제 위 함수에 대한 테스트 코드를 pytest 형태로 작성해보겠습니다. 정상 동작(예: 5의 팩토리얼은 120)과 예외 동작(음수 입력 시 ValueError) 두 가지를 검증하는 테스트를 만들어보죠:

```python
# test_factorial.py - pytest 스타일의 테스트 코드
import pytest
from factorial import factorial

def test_factorial_basic():
    # 일반 사례: 5! = 120, 그리고 0! = 1, 1! = 1
    assert factorial(5) == 120
    assert factorial(1) == 1
    assert factorial(0) == 1

def test_factorial_negative():
    # 음수 입력 시 예외 발생 여부 확인
    with pytest.raises(ValueError):
        factorial(-3)
```

위의 `test_factorial_basic` 함수는 `factorial`이 올바른 값을 반환하는지 검증하고, `test_factorial_negative` 함수는 음수 입력에 대해 `ValueError`가 발생하는지를 `pytest.raises` 컨텍스트 매니저로 검증합니다. pytest에서는 이렇게 테스트 함수들을 작성한 후, **터미널에서 `pytest` 명령**을 실행하면 `test_*.py` 파일의 모든 테스트 함수를 찾아 자동으로 실행합니다. 모든 테스트가 통과하면 터미널에 **`========= 2 passed in 0.01s =========`** 와 같이 표시되고, 하나라도 실패하면 어떤 입력에서 예상과 다른 결과가 나왔는지 오류 메시지가 출력됩니다.

> 💡 **unittest 스타일로 작성한다면?** 위와 같은 테스트를 `unittest`로 작성하려면 `TestFactorial`이라는 테스트 케이스 클래스를 만들고 그 안에 메서드로 `test_factorial_basic`, `test_factorial_negative`를 정의합니다. 그리고 `assert` 대신 `self.assertEqual`이나 `self.assertRaises`를 사용합니다. 실행은 `python -m unittest`로 할 수 있습니다. 스타일은 다르지만 본질은 pytest와 동일합니다.

## 4. GitHub Copilot을 활용한 테스트 케이스 자동 생성하기

이제 GitHub Copilot을 이용하여 **테스트 코드를 자동으로 생성**하는 방법을 알아보겠습니다. **GitHub Copilot**은 OpenAI Codex 기반의 AI 코드 도우미로, 주석이나 함수 시그니처 등 **문맥을 파악하여 코드 조각을 제안**해줍니다. 이를 테스트 작성에 활용하면, 함수의 구현을 바탕으로 적절한 테스트 케이스를 Copilot이 생성해주므로 일일이 테스트 시나리오를 생각하지 않아도 되어 편리합니다. Copilot으로 테스트를 만들어내는 주요 방법은 다음과 같습니다:

- **에디터 명령 활용**: VS Code에서 함수 구현 코드를 **범위 선택(드래그)** 한 후 Command Palette에서 **“Copilot: Generate tests”** 명령 (또는 Copilot Chat 창에서 **`/test`** 명령)을 실행하면, Copilot이 해당 코드에 대한 테스트 코드를 자동 생성하여 제시합니다.  
- **주석 프롬프트 활용**: 코드 편집 중에 자연어 주석을 사용해 Copilot에게 의도를 전달할 수도 있습니다. 예를 들어 함수 아래에 `# 이 함수에 대한 단위 테스트 작성` 과 같은 주석을 적으면, Copilot이 이를 읽고 다음 줄에 해당 함수를 검증하는 테스트 코드 블럭을 제안합니다. 혹은 별도의 테스트 파일을 만들고 `def test_...`를 타이핑하기 시작하면 Copilot이 앞서 정의된 함수의 이름과 동작에 맞는 테스트 함수를 자동 완성해주는 경우도 많습니다.

Copilot을 통해 생성된 테스트 코드는 개발자가 일반적으로 작성해야 할 여러 케이스를 포함하고 있으므로, 테스트 아이디어를 놓치지 않도록 도와주는 장점이 있습니다. 예를 들어, 아래와 같은 나누기 함수 `divide`가 있다고 가정해보겠습니다:

```python
# example.py - 테스트 대상 함수
def divide(a: float, b: float) -> float:
    """a를 b로 나눈 결과를 반환한다. 0으로 나누는 경우 ValueError 발생."""
    if b == 0:
        raise ValueError("0으로 나눌 수 없습니다.")
    return a / b
```

위 함수를 Copilot에게 테스트하도록 요청하면, 다음과 같은 단위 테스트 코드를 자동 생성해줄 수 있습니다 (여기서는 `unittest` 스타일로 예시):

```python
# Copilot이 생성한 테스트 예시 (unittest 기반)
import unittest
from example import divide

class TestDivide(unittest.TestCase):
    def test_divide_normal(self):
        self.assertEqual(divide(6, 3), 2)          # 6/3=2
        self.assertAlmostEqual(divide(5, 2), 2.5)  # 5/2=2.5 (부동소수 비교)
        self.assertEqual(divide(-4, 2), -2)        # -4/2=-2

    def test_divide_by_zero(self):
        with self.assertRaises(ValueError):
            divide(5, 0)
```

Copilot이 생성한 이 테스트 코드를 보면, **일반적인 경우**(6÷3, 5÷2, -4÷2)에 대한 검증과, **엣지 케이스**인 0으로 나누는 경우에 대한 예외 발생 검증까지 폭넓게 다루고 있습니다. 개발자가 직접 테스트를 작성했다면 놓쳤을 법한 시나리오(예를 들어 음수 입력 처리나 부동소수점 결과 확인 등)도 Copilot이 문맥을 바탕으로 자동으로 포함해준 것을 볼 수 있습니다. 이처럼 Copilot은 함수의 구현 내용을 분석하여 적절한 입력 값과 예상 결과 쌍을 생성해주기 때문에, **테스트 커버리지**를 손쉽게 높이는 데 도움을 줍니다.

물론 Copilot의 출력이 100% 완벽하다고 단정할 수는 없습니다. Copilot이 제안한 테스트 코드는 항상 **개발자의 검토**를 거쳐야 하며, 잘못된 가정이나 불필요한 부분은 수정하거나 삭제해야 합니다. 하지만 전체적인 틀을 잡아주고 여러 케이스를 빠르게 만들어주므로, 이를 기반으로 약간의 수정을 거쳐 자신만의 테스트 스위트를 완성하면 됩니다.

> 💡 **Copilot 팁:** 함수에 대한 **Docstring**이나 주석으로 제약사항과 의도를 명확히 적어두면 Copilot이 더 좋은 품질의 테스트 코드를 제안합니다. 예를 들어 `"0으로 나누면 ValueError 발생"`과 같은 설명이 함수에 있다면, 이를 읽은 Copilot은 예외 상황 테스트를 더 확실히 포함해줄 것입니다.

## 5. Copilot Chat을 활용한 테스트 작성 지원 및 리팩토링

위에서 살펴본 Copilot의 기본 완성 기능 외에, **Copilot Chat**이라는 대화형 도구를 사용하면 테스트 코드를 작성하고 개선하는 과정을 더욱 **능동적으로 보조**받을 수 있습니다. Copilot Chat은 마치 페어 프로그래머처럼, 우리가 자연어로 던지는 질문이나 명령에 따라 코드를 생성하거나 리팩토링해주는 기능입니다. 이 채팅 인터페이스를 활용해 테스트 작성에 도움받는 방법을 알아볼까요?

**1) 자연어로 테스트 생성 요청하기:** Copilot Chat 창에 해당 함수에 대한 단위 테스트 생성을 요청하면 됩니다. 예를 들어 *"`reverse_string` 함수에 대한 단위 테스트 코드를 작성해줘"* 라고 물어보면, Copilot은 그 함수의 의도와 구현을 분석하여 적절한 테스트 케이스들을 가진 코드를 답변으로 제공합니다. 이전 섹션의 `/test` 명령과 유사하지만, Chat을 통해서는 추가로 "**특정 시나리오도 포함해줘**" 같이 세부 요구사항을 자연어로 더 덧붙일 수도 있습니다. Copilot Chat은 대화 문맥을 기억하기 때문에, 처음에 생성된 테스트 코드를 보고 **"엣지 케이스도 추가해줘"** 또는 **"다른 입력 조합도 테스트해볼까?"** 같은 추가 요구를 연이어 할 수도 있습니다. 그러면 Copilot은 기존 답변을 보강하는 형태로 코드를 조정해 줍니다.

**2) 작성된 테스트 코드 리팩토링하기:** Copilot Chat은 이미 작성한 코드의 개선점도 제안할 수 있습니다. 예를 들어 여러 테스트 함수에 중복된 코드가 있다면, Chat에게 **"테스트 코드의 중복을 줄이도록 리팩터링해줘"* 또는 *"pytest의 parametrize를 사용해서 리팩토링할 수 있을까?"** 라고 요청해볼 수 있습니다. 그러면 Copilot은 테스트 코드의 구조를 분석하여, 더 간결하고 효율적인 형태로 변환된 코드를 제시합니다.  

구체적으로, 앞서 Copilot이 생성한 `TestDivide` 클래스의 테스트 코드에는 `divide(6,3)`, `divide(5,2)`, `divide(-4,2)`를 각각 개별 assert로 검사하고 있었는데요. 이를 **pytest**의 `@pytest.mark.parametrize` 기능을 사용하여 하나의 테스트 함수로 합칠 수도 있습니다. Copilot Chat에게 *"위 테스트들을 pytest parametrize를 사용해 리팩토링해줘"* 라고 지시하면, 예를 들어 다음과 같은 개선된 코드를 제안받을 수 있습니다:

```python
# Copilot Chat이 제안한 pytest 스타일 리팩토링 예시
import pytest
from example import divide

@pytest.mark.parametrize("a, b, expected", [
    (6, 3, 2),
    (5, 2, 2.5),
    (-4, 2, -2),
])
def test_divide_various(a, b, expected):
    assert divide(a, b) == expected

def test_divide_by_zero():
    with pytest.raises(ValueError):
        divide(a=5, b=0)
```

위와 같이 리팩토링하면, 여러 입력 케이스를 일일이 개별 함수로 나눌 필요 없이 하나의 테스트 함수에 **매개변수화된 형태**로 표현할 수 있습니다. `@pytest.mark.parametrize` 데코레이터는 지정된 인자 목록을 바탕으로 `test_divide_various` 함수를 여러 번 실행하여 각각 `a, b, expected` 값을 넣어주므로, 코드 중복 없이 동일한 로직의 다양한 상황을 검사할 수 있습니다. Copilot Chat은 이런 파이썬 고급 테스트 기법도 활용해볼 수 있다는 점을 알려주고 코드 예시를 직접 제공함으로써, 개발자가 테스트 코드를 더욱 깔끔하게 개선할 수 있도록 도와줍니다.

**3) 그 밖의 활용**: Copilot Chat은 이외에도 **테스트 실패 원인 분석**, **함수 동작 설명**, **코드 수정 제안** 등 다양한 맥락에서 유용합니다. 예를 들어 테스트가 실패했는데 원인을 모르겠다면 *"이 실패한 테스트의 원인이 무엇인지 알려줘"*라고 질문해보세요. Copilot이 실패 메시지나 코드를 근거로 문제점을 추측하고 해결 방향을 제안해줄 수도 있습니다. 마찬가지로 *"이 함수의 복잡도를 낮추는 방향으로 리팩터링해줘"* 등의 요청을 통해 코드 품질 개선을 도울 수도 있습니다. 

Copilot Chat을 잘 활용하면 테스트 코드 작성과 개선 과정이 마치 동료와 함께 작업하는 것처럼 수월해집니다. Chat의 답변을 맹신하기보다는 **가이드로 참고**하고, 최종 결정을 개발자가 내리는 것이 중요하지만, 아이디어가 부족할 때나 빠른 대안이 필요할 때 강력한 조력자가 되어줄 것입니다.

> 💡 **Note:** Copilot Chat 기능을 사용하려면 VS Code에서 **GitHub Copilot Chat 확장**을 설치하고 GitHub 계정으로 로그인해야 합니다. Chat은 프리뷰(Preview) 기능일 수 있으므로 사전 가입이 필요할 수도 있습니다. Chat 창에서 코드 조각을 보내면 해당 코드에 대한 맥락을 인식하여 답변하니, 질문 전에 테스트하고자 하는 함수나 코드 블록을 선택해 **`Add to chat`**(코드 첨부) 기능을 사용하면 더욱 정확한 응답을 얻을 수 있습니다.

## 6. 실습: 간단한 함수에 대한 테스트 작성하기

이제 이론 설명을 마쳤으니, 직접 손을 움직여 **테스트 자동화 실습**을 해볼 차례입니다. 여기서는 두 가지 간단한 함수를 대상으로 테스트 코드를 작성하는 연습을 합니다. 각 예제에서는 함수 구현과 다양한 입력에 대한 테스트를 작성해볼 것이며, 가능하면 GitHub Copilot의 도움을 받아 자동완성과 Chat을 활용해봅시다.

### 실습 1: 문자열 뒤집기 함수 테스트하기

첫 번째 연습은 **문자열을 거꾸로 뒤집는 함수**를 작성하고 이에 대한 테스트를 만드는 것입니다. 파이썬에서는 문자열을 뒤집는 간단한 방법으로 슬라이싱 `[::-1]`를 활용할 수 있습니다.

1. **함수 구현**: VS Code에서 `utils.py` (또는 원하는 파일 이름) 파일을 만들고, 다음과 같이 `reverse_string` 함수를 구현합니다. (이 함수는 입력 문자열을 거꾸로 뒤집어 반환합니다.)

   ```python
   # utils.py
   def reverse_string(s: str) -> str:
       """주어진 문자열을 거꾸로 뒤집어서 반환한다."""
       return s[::-1]
   ```

2. **테스트 파일 생성**: 이제 같은 프로젝트 폴더에 `test_utils.py` 파일을 만들고, pytest 형식의 테스트 코드를 작성해봅시다. 파일 상단에는 `from utils import reverse_string`으로 함수를 임포트하고, 아래에 `test_`로 시작하는 여러 함수를 작성할 예정입니다.

3. **테스트 케이스 구상**: 문자열 뒤집기 함수에 대해 생각해볼 수 있는 여러 입력 상황을 테스트해보세요. 예를 들면:  
   - 일반적인 문자열: `"hello"` → `"olleh"`가 나오는지 확인  
   - 빈 문자열: `""` → `""` (빈 문자열은 뒤집어도 그대로 빈 문자열이어야 함)  
   - 다국어/유니코드 문자열: `"안녕"` → `"녕안"` (한글과 같은 문자열도 제대로 뒤집히는지 확인)  
   - 대칭인 문자열: `"level"` → `"level"` (뒤집었을 때 동일한 경우도 처리 가능)  

   위와 같은 시나리오들을 각각 별도의 테스트 함수로 만들거나, 하나의 테스트 함수에서 여러 `assert`로 검증할 수 있습니다. 어떤 방식이든 상관없지만 **각 경우의 예상 결과가 명확히 드러나도록** 코드를 작성해보세요.

4. **Copilot의 도움 받기**: 한 가지 테스트 함수를 직접 작성한 후에 Copilot의 자동완성 제안을 확인해보세요. 예를 들어 아래와 같이 테스트 함수의 일부를 타이핑하면 Copilot이 이어서 완성안을 제시할 수 있습니다. 필요하면 수정을 가하면서 제안을 받아들입니다.

   ```python
   # test_utils.py 중 일부
   from utils import reverse_string

   def test_reverse_string_basic():
       assert reverse_string("hello") == "olleh"
       assert reverse_string("") == ""
   ```

   위 코드를 직접 작성하거나 Copilot의 제안을 통해 얻을 수 있습니다. Copilot이 여기까지 자동으로 채워줬다면, 이어서 다른 케이스도 제안해줄 수 있습니다. `assert reverse_string("안녕") == "녕안"`과 같은 테스트도 추가해보세요. 만약 Copilot이 제안을 하지 않는다면, 직접 해당 줄을 작성해도 좋습니다. 또는 Copilot Chat에 *"reverse_string 함수에 대한 다른 테스트 케이스를 추가해줘"*라고 요청해서 나온 아이디어를 참고해도 됩니다.

5. **테스트 실행 및 확인**: 테스트 코드를 다 작성했다면, VS Code 터미널에서 `pytest` 명령을 실행하여 테스트를 돌려봅니다. 모든 테스트가 **녹색 Pass**로 통과하면 성공입니다! 하나라도 실패한다면 `reverse_string` 구현이나 테스트 기대값에 오류가 없는지 확인합니다.

예상되는 `test_utils.py`의 한 예시는 다음과 같습니다:

```python
# test_utils.py (예시 풀이)
from utils import reverse_string

def test_reverse_string_basic():
    assert reverse_string("hello") == "olleh"

def test_reverse_string_empty():
    assert reverse_string("") == ""

def test_reverse_string_unicode():
    assert reverse_string("안녕") == "녕안"
```

위 테스트들은 각각 일반 문자열, 빈 문자열, 유니코드 문자열 케이스를 검증합니다. 모두 통과했다면 `reverse_string` 함수는 요구사항대로 동작하고 있다고 볼 수 있습니다.

### 실습 2: 숫자 리스트 평균 계산 함수 테스트하기

두 번째 연습으로, **숫자 리스트의 평균을 계산하는 함수**를 테스트해보겠습니다. 이번에도 함수를 작성하고 다양한 입력에 대한 결과를 검증합니다.

1. **함수 구현**: `utils.py` (혹은 별도 파일)에 `average(numbers: list[float]) -> float` 함수를 구현합니다. 만약 빈 리스트가 입력되면 처리 방법을 정해야 하는데, 여기서는 **빈 리스트 입력 시 `ValueError`를 일으킨다**고 가정해보겠습니다. 함수 코드는 다음과 같습니다.

   ```python
   # utils.py (추가 구현)
   def average(numbers: list[float]) -> float:
       """숫자 목록의 평균을 반환한다. 빈 리스트인 경우 ValueError 발생."""
       if not numbers:
           raise ValueError("리스트가 비어있습니다.")
       return sum(numbers) / len(numbers)
   ```

2. **테스트 케이스 구상**: 이제 `test_utils.py` (또는 별도 `test_average.py`)에 위 함수의 테스트를 추가합니다. 고려할 만한 테스트 시나리오는:  
   - **일반적인 경우**: `[1, 2, 3]`의 평균은 `2.0`처럼, 몇 가지 숫자 리스트에 대한 정확한 평균값 확인  
   - **소수 포함 경우**: `[2.5, 3.5, 4.0]` → `3.333...` 등 부동소수 입력 처리 (필요시 `pytest.approx`를 사용해 근사 비교)  
   - **음수 포함 경우**: `[-1, 1]` → `0.0` 같은 음수와 양수가 섞인 경우  
   - **엣지 케이스**: `[]` 빈 리스트 입력 시 `ValueError` 발생 여부 검증  

3. **테스트 작성 및 Copilot 활용**: 위의 시나리오를 각각 코드로 옮겨봅시다. Copilot이 이전 맥락을 참고하여 자동완성을 제공할 수 있으니, 몇 개의 `assert`를 직접 쓰고 나머지 제안을 받아도 됩니다. 예를 들어 `def test_average_basic():`를 쓰고 `[1,2,3]` 케이스를 작성하면, 다음 줄에 `[2,4,6]` 등의 추가 사례를 Copilot이 제안할 수도 있습니다. 제안을 받아들이거나 필요하면 직접 추가하세요. 빈 리스트의 예외 검증은 `with pytest.raises(ValueError): average([])` 형태로 작성하면 됩니다.

4. **실행 및 검증**: 모든 테스트를 작성했다면 `pytest`로 실행해 확인합니다. 평균 계산은 부동소수 연산이 있으므로 아주 미세한 오차가 날 수 있지만, 본 연습에서는 큰 문제 없이 떨어지는 숫자들로 테스트해볼 것입니다. 테스트가 통과하면 성공입니다. 실패한 케이스가 있다면 함수 로직이나 테스트의 기대치를 수정해야겠죠.

참고로, 완성된 테스트 코드의 예시는 아래와 같습니다:

```python
# test_utils.py (average 함수에 대한 테스트 추가 예시)
from utils import average
import pytest

def test_average_basic():
    assert average([1, 2, 3]) == 2.0
    assert average([2, 4, 6]) == 4.0

def test_average_with_negative():
    assert average([-1, 1, 1, -1]) == 0.0

def test_average_float_values():
    result = average([2.5, 3.5, 4.0]) 
    # 부동소수 비교: 3.333... 근처 값인지 확인
    assert pytest.approx(result, rel=1e-3) == 3.3333

def test_average_empty_list():
    with pytest.raises(ValueError):
        average([])
```

위 테스트들은 여러 가지 리스트 입력에 대해 `average` 함수의 동작을 검증합니다. Copilot을 활용했다면 상당 부분 자동으로 완성되었을 것이고, 직접 작성했더라도 이전의 `reverse_string` 예제와 비슷한 원리로 작성할 수 있었을 것입니다.

이러한 실습을 통해 **테스트 대상 코드의 요구사항을 파악하고, 다양한 입력과 상황을 고려한 테스트 케이스를 작성**하는 경험을 쌓아보았습니다. 처음에는 간단한 함수들이지만, 원리를 익히면 더 복잡한 모듈이나 클래스에 대해서도 입력-출력 관계를 정리하여 테스트를 설계할 수 있게 됩니다. 또한 Copilot의 제안을 통해 테스트 아이디어를 얻고 생산성을 높일 수 있음을 직접 체험해보셨길 바랍니다.

## 7. 테스트 커버리지와 지속적 통합(CI) 연관성

마지막으로, 이렇게 작성한 테스트들을 프로젝트의 품질 관리에 어떻게 활용하는지 간단히 살펴보겠습니다.

**테스트 커버리지(Test Coverage)**는 전체 코드 중 얼마나 많은 부분이 테스트되었는지를 나타내는 지표입니다. 예를 들어 함수 10개 중 8개에 테스트가 있다면 함수 커버리지는 80%로 볼 수 있으며, 코드 라인 기준으로 산출하기도 합니다. 커버리지가 높을수록 테스트되지 않은 (즉, 잠재적으로 검증이 안 된) 부분이 적다는 뜻이므로 일반적으로는 높은 커버리지를 추구합니다. 파이썬에서는 `coverage.py` 도구나 `pytest --cov` 옵션을 사용하여 테스트 실행 시 커버리지를 측정할 수 있습니다. 커버리지 보고서를 통해 어떤 함수나 라인이 테스트되지 않았는지 파악하고, Copilot의 도움을 받아 **누락된 부분의 테스트를 추가 작성**하면 코드 품질을 한층 높일 수 있습니다. 물론 커버리지 **숫자 자체가 절대적인 품질 척도는 아니기 때문에**, 100%에 집착하기보다는 중요한 로직을 빠짐없이 테스트하는 데 중점을 두세요.

또한, 실무 개발에서 작성된 테스트 코드는 **지속적 통합(Continuous Integration, CI)** 프로세스와 결합되어 활용됩니다. CI란 코드 변경이 발생할 때마다 자동으로 빌드와 테스트를 수행하여 문제를 빠르게 검출하는 개발 문화입니다. 예를 들어 GitHub에 코드를 푸시하거나 Pull Request를 만들면, **GitHub Actions**와 같은 CI 도구가 미리 설정된 워크플로우에 따라 `pytest` 등을 실행해 모든 테스트를 돌립니다. 만약 새로운 커밋으로 인해 테스트 중 하나라도 실패하면 CI 결과가 빨간불로 표시되고, 해당 변경을 머지(merge)하거나 배포하기 전에 문제를 해결하도록促합니다. 이를 통해 **테스트 자동화**는 CI 파이프라인에서 **코드 품질 게이트** 역할을 하며, 팀 전체의 코드 안정성을 유지시켜 줍니다. 테스트가 모두 통과하면 비로소 빌드가 성공했다는 신호로 간주되어 이후 단계(배포 등)로 이어질 수 있습니다.

정리하면, 자동화된 테스트를 충분히 작성해두면 **코드 변경에 따른 위험을 최소화**할 수 있고, CI 환경에서 매번 빠르고 일관된 검증을 거치므로 개발 워크플로우의 신뢰성이 크게 향상됩니다. GitHub Copilot과 같은 도구는 이러한 테스트 작성 과정을 도와주는 든든한 동반자이며, 빠른 개발 속도와 높은 코드 품질을 동시에 추구할 수 있게 해줍니다. 
